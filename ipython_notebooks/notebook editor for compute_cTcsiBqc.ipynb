{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-py36_mlflow",
      "display_name": "Python (env py36_mlflow)",
      "language": "python"
    },
    "associatedRecipe": "compute_cTcsiBqc",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "admin"
      },
      "lastModifiedOn": 1658215676124
    },
    "creator": "admin",
    "createdOn": 1658215676124,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.6.15",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 1,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\nimport shutil\nimport dataiku\nimport pandas as pd\nimport mlflow\nfrom sklearn.linear_model import LogisticRegression"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "/Users/christelleren/DSS/design/code-envs/python/py36_mlflow/lib/python3.6/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n  warnings.warn(msg)\n/Users/christelleren/DSS/design/code-envs/python/py36_mlflow/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: MLflow support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use MLflow will continue to work without modification, but Python 3.6 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3.7 or newer.\n  \"\"\"\n",
          "name": "stderr"
        }
      ]
    },
    {
      "execution_count": 2,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from dss_mlflow import preprocessing"
      ],
      "outputs": []
    },
    {
      "execution_count": 3,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "client \u003d dataiku.api_client()\nproject \u003d client.get_default_project()"
      ],
      "outputs": []
    },
    {
      "execution_count": 4,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# get train dataset\ntrain_dataset \u003d dataiku.Dataset(\"training_data\")\nevaluation_dataset \u003d dataiku.Dataset(\"eval_data\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 5,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# get output saved model\nsm \u003d project.get_saved_model(\"VdHxdbkg\")\n\n# get train dataset as a pandas dataframe\ndf \u003d train_dataset.get_dataframe()"
      ],
      "outputs": []
    },
    {
      "execution_count": 6,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# get the path of a local managed folder where to temporarily save the trained model\nmf \u003d dataiku.Folder(\"cTcsiBqc\")\npath \u003d mf.get_path()\n\nmodel_subdir \u003d \"my_subdir\"\nmodel_dir \u003d os.path.join(path, model_subdir)"
      ],
      "outputs": []
    },
    {
      "execution_count": 7,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "A, b \u003d preprocessing.clean_df(df)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name \u0027pd\u0027 is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-7-000b7ea8316c\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/DSS/design/config/projects/MASTERCODE/lib/python/dss_mlflow/preprocessing.py\u001b[0m in \u001b[0;36mclean_df\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u0027y\u0027\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 7\u001b[0;31m     \u001b[0mjob_df\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;34m\u0027job\u0027\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmarital_df\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarital\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;34m\u0027marital\u0027\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0meducation_df\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meducation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;34m\u0027education\u0027\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name \u0027pd\u0027 is not defined"
          ]
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y \u003d df[\u0027y\u0027]\nX \u003d df.drop(\u0027y\u0027, axis\u003d1)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "job_df \u003d pd.get_dummies(df.job, prefix\u003d\u0027job\u0027)\nmarital_df \u003d pd.get_dummies(df.marital, prefix\u003d\u0027marital\u0027)\neducation_df \u003d pd.get_dummies(df.education, prefix\u003d\u0027education\u0027)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0
        ]
      },
      "source": [
        "month_dic \u003d {\n    \u0027apr\u0027: 5,\n    \u0027aug\u0027: 8,\n    \u0027dec\u0027: 12,\n    \u0027feb\u0027: 2,\n    \u0027jan\u0027: 1,\n    \u0027jul\u0027: 7,\n    \u0027jun\u0027: 6,\n    \u0027mar\u0027: 3,\n    \u0027may\u0027: 5,\n    \u0027nov\u0027: 11,\n    \u0027oct\u0027: 10,\n    \u0027sep\u0027: 9}"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X.drop([\u0027job\u0027, \u0027marital\u0027, \u0027education\u0027], axis\u003d1, inplace\u003dTrue)\nX \u003d pd.concat([X, job_df, marital_df, education_df], axis\u003d1)\nX.month.replace(month_dic, inplace\u003dTrue)\nX.replace({\"no\": 0, \"yes\": 1}, inplace\u003dTrue)\nclf \u003d LogisticRegression(random_state\u003d0).fit(X, y)"
      ],
      "outputs": []
    },
    {
      "execution_count": 4,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from dss_mlflow import preprocessing"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named \u0027dss_mlflow\u0027",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-4-557e77159024\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdss_mlflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named \u0027dss_mlflow\u0027"
          ]
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if os.path.exists(model_dir):\n    shutil.rmtree(model_dir)\n\ntry:\n    # ...train your model...\n    clf \u003d LogisticRegression(random_state\u003d0).fit(X, y)\n\n    # ...save it with package specific MLflow method (here, SKlearn)...\n    mlflow.sklearn.save_model(clf, model_dir)\n\n    # import the model, creating a new version\n    mlflow_version \u003d sm.import_mlflow_version_from_managed_folder(\"v03\", \"cTcsiBqc\", model_subdir, \"py36_mlflow\")\nfinally:\n    shutil.rmtree(model_dir)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# setting metadata (target name, classes,...)\nmlflow_version.set_core_metadata(target_column_name\u003d\"y\",\n                             class_labels\u003d[\"no\", \"yes\"],\n                             get_features_from_dataset\u003d\"eval_data_prepared\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# evaluate the performance of this new version, to populate the performance screens of the saved model version in DSS\nmlflow_version.evaluate(\"eval_data_prepared\")"
      ],
      "outputs": []
    }
  ]
}